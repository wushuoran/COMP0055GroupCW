{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import bisect"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Import Training, Testing and Validating Set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori train  1319\n",
      "matrix train  1319\n",
      "ori train y  1319\n",
      "matrix train y  1319\n",
      "[[2.00900000e+03 0.00000000e+00 2.52077562e-01 2.22222222e-03\n",
      "  1.14221725e-01 6.87422107e-04 9.79591837e-01 9.89711711e-05\n",
      "  2.10892236e-01 1.60000000e-03 9.79166667e-01 1.74114916e-01\n",
      "  9.79381443e-01 0.00000000e+00 1.80413125e-03 1.54066216e-05\n",
      "  5.50724638e-01 5.36842105e-01 7.75316456e-01 6.47342995e-01]]\n",
      "0.6736242884250474\n"
     ]
    }
   ],
   "source": [
    "poi_train_x = pd.read_csv('train_X.csv')\n",
    "print(\"ori train \", poi_train_x.shape[0])\n",
    "poi_train_x = np.matrix(poi_train_x.to_numpy())\n",
    "print(\"matrix train \", len(poi_train_x))\n",
    "poi_train_y = pd.read_csv('train_y.csv')\n",
    "print(\"ori train y \", poi_train_y.shape[0])\n",
    "poi_train_y = poi_train_y['Life Expectancy'].tolist()\n",
    "print(\"matrix train y \", len(poi_train_y))\n",
    "poi_test_x = pd.read_csv('test_X.csv')\n",
    "poi_test_x = np.matrix(poi_test_x.to_numpy())\n",
    "poi_test_y = pd.read_csv('test_y.csv')\n",
    "poi_test_y = poi_test_y['Life Expectancy'].tolist()\n",
    "poi_val_x = pd.read_csv('val_X.csv')\n",
    "poi_val_x = np.matrix(poi_val_x.to_numpy())\n",
    "poi_val_y = pd.read_csv('val_y.csv')\n",
    "poi_val_y = poi_val_y['Life Expectancy'].tolist()\n",
    "\n",
    "print (poi_train_x[0])\n",
    "print (poi_train_y[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define Main Arguments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Posion count:  300  Train count:  1319  Test count:  165  Proportion of poisoning:  0.1852995676343422\n"
     ]
    }
   ],
   "source": [
    "# num of poisoning points\n",
    "poison_ct = 300\n",
    "# num of points to train model\n",
    "train_ct = len(poi_train_x)\n",
    "test_ct = len(poi_test_x)\n",
    "# proportion of poisoning\n",
    "total_prop = poison_ct / (poison_ct + train_ct)\n",
    "print (\"Posion count: \", poison_ct, \" Train count: \", train_ct, \" Test count: \", test_ct, \" Proportion of poisoning: \", total_prop)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Inf_flip Function"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_opp [0. 0. 0. ... 0. 0. 0.]\n",
      "stats [0. 0. 0. ... 0. 0. 0.]\n",
      "total_prob 132.78026565464893\n",
      "x_pois len:  300\n",
      "x_pois col ct: 20\n",
      "y_pois len:  300\n"
     ]
    }
   ],
   "source": [
    "# First calculates the dot product of the transpose of training set and training set using the np.dot() function\n",
    "dot_product = np.dot(poi_train_x.T, poi_train_x)\n",
    "# Then, it adds a scaled identity matrix to the resulting square matrix. The scaling factor is 0.01.\n",
    "# The identity matrix is created using the np.eye() function with a size equal to the number of columns in training set.\n",
    "scal_id_matrix = 0.01 * np.eye(poi_train_x.shape[1])\n",
    "# Calculates the inverse of a matrix inv_cov using the training set and the identity matrix np.eye().\n",
    "# Then takes the inverse of the resulting matrix using the ** -1 notation.\n",
    "# This results in the inv_cov matrix, which can be used in various linear algebraic operations.\n",
    "# The inverse of the covariance matrix is used in various algorithms to estimate the regression coefficients, compute prediction intervals, or perform principal component analysis, among other things.\n",
    "inv_cov = (dot_product + scal_id_matrix) ** -1\n",
    "# The resulting matrix is then multiplied by the transpose of poi_train_x using poi_train_x.T. This is equivalent to computing poi_train_x times inv_cov times poi_train_x transpose.\n",
    "# The resulting matrix H represents the projection of the training data onto a lower-dimensional space that captures the most important information or variance in the data\n",
    "H = poi_train_x @ inv_cov @ poi_train_x.T\n",
    "# row sum of H\n",
    "row_sum = np.sum(H, axis=1)\n",
    "train_y_arr = np.array(poi_train_y)\n",
    "# computes an auxiliary array that measures uncertainty in the target y\n",
    "y_uncert = np.abs(train_y_arr - 0.4) + 0.4\n",
    "'''\n",
    "num_differences = np.count_nonzero(train_y_arr != y_uncert)\n",
    "proportion_differences = num_differences / np.size(train_y_arr)\n",
    "print(\"difference \",proportion_differences)\n",
    "'''\n",
    "# computes an auxiliary array that represents the \"flip\" or opposite of the target y\n",
    "y_opp = 1 - np.floor(0.5 + train_y_arr)\n",
    "print(\"y_opp\",y_opp)\n",
    "# combines the projection strength and uncertainty measures for each instance into a single statistic that captures the trade-off between projection quality and target uncertainty.\n",
    "# stat = np.multiply(bests.ravel(), room.ravel())\n",
    "stats = (y_uncert * y_opp).flatten()\n",
    "print(\"stats\",stats)\n",
    "# Compute the total probability of all instances\n",
    "total_prob = sum(stats)\n",
    "print(\"total_prob\", total_prob)\n",
    "# Initialize a list all_prob with a zero value.\n",
    "all_prob = [0]\n",
    "# Initialize an empty list to store the selected instance indices.\n",
    "poi_idx = []\n",
    "#for i in range(len(poi_train_x)):\n",
    "#    all_prob.append(stats[i] + all_prob[-1])\n",
    "all_prob = [sum(stats[:i+1]) for i in range(poi_train_x.shape[0])]\n",
    "poi_idx = [bisect.bisect_left(all_prob, np.random.uniform(low=0, high=total_prob)) for i in range(poison_ct)]\n",
    "\n",
    "x_pois = poi_train_x[poi_idx]\n",
    "y_pois = [y_opp[i] for i in poi_idx]\n",
    "\n",
    "#print(\"x_pois: \", x_pois)\n",
    "print(\"x_pois len: \", len(x_pois))\n",
    "print(\"x_pois col ct:\",x_pois.shape[1])\n",
    "#print(\"y_pois: \", y_pois)\n",
    "print(\"y_pois len: \", len(y_pois))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
